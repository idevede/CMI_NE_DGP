{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy.linalg import det\n",
    "\n",
    "import CMINE_lib as CMINE\n",
    "# from Guassian_variables import Data_guassian\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import itertools\n",
    "\n",
    "np.random.seed(37)\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import math\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(value, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable implementation of the operation\n",
    "    value.exp().sum(dim, keepdim).log()\n",
    "    \"\"\"\n",
    "    # TODO: torch.max(value, dim=None) threw an error at time of writing\n",
    "    if dim is not None:\n",
    "        m, _ = torch.max(value, dim=dim, keepdim=True)\n",
    "        value0 = value - m\n",
    "        if keepdim is False:\n",
    "            m = m.squeeze(dim)\n",
    "        return m + torch.log(torch.sum(torch.exp(value0),\n",
    "                                       dim=dim, keepdim=keepdim))\n",
    "    else:\n",
    "        m = torch.max(value)\n",
    "        sum_exp = torch.sum(torch.exp(value - m))\n",
    "        if isinstance(sum_exp, Number):\n",
    "            return m + math.log(sum_exp)\n",
    "        else:\n",
    "            return m + torch.log(sum_exp)\n",
    "\n",
    "class L1OutUB(nn.Module):  # naive upper bound\n",
    "    def __init__(self, x_dim, y_dim, hidden_size):\n",
    "        super(L1OutUB, self).__init__()\n",
    "        self.p_mu = nn.Sequential(nn.Linear(x_dim, hidden_size//2),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_size//2, y_dim))\n",
    "\n",
    "        self.p_logvar = nn.Sequential(nn.Linear(x_dim, hidden_size//2),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_size//2, y_dim),\n",
    "                                       nn.Tanh())\n",
    "\n",
    "        self.p_mu_neg = nn.Sequential(nn.Linear(x_dim-1, hidden_size//2),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_size//2, y_dim))\n",
    "\n",
    "        self.p_logvar_neg = nn.Sequential(nn.Linear(x_dim-1, hidden_size//2),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hidden_size//2, y_dim),\n",
    "                                       nn.Tanh())\n",
    "\n",
    "\n",
    "    def get_mu_logvar(self, x_samples):\n",
    "        mu = self.p_mu(x_samples)\n",
    "        logvar = self.p_logvar(x_samples)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def get_mu_logvar_neg(self, x_samples):\n",
    "        mu = self.p_mu_neg(x_samples)\n",
    "        logvar = self.p_logvar_neg(x_samples)\n",
    "        return mu, logvar\n",
    "\n",
    "    def forward(self, x_samples, y_samples): # x_samples = s_t, a ; y_samples = s_{t+1}\n",
    "        batch_size = y_samples.shape[0]\n",
    "        #x_samples[:, 1].masked_fill_(x_samples[:, 1]!=0, float(0))\n",
    "        mu, logvar = self.get_mu_logvar(x_samples)\n",
    "\n",
    "        positive = (- (mu - y_samples)**2 /2./logvar.exp() - logvar/2.).sum(dim = -1) #[nsample]\n",
    "\n",
    "        negative = []\n",
    "        for i in range(x_samples.shape[1]-1):\n",
    "            result = []\n",
    "            for j in range(x_samples.shape[1]): \n",
    "                if j != i:\n",
    "                    result.append(j)\n",
    "            \n",
    "            x_temp = torch.index_select(x_samples, dim=1, index=torch.tensor(result).cuda())\n",
    "            #x_temp = x_samples.index_fill_(1, torch.tensor([i]).cuda(), float('0'))\n",
    "            mu, logvar = self.get_mu_logvar_neg(x_temp)\n",
    "            neg = (- (mu - y_samples)**2 /2./logvar.exp() - logvar/2.).sum(dim = -1) #[nsample]\n",
    "            if i == 0:\n",
    "                negative = neg.unsqueeze(-1)\n",
    "            else:\n",
    "                negative = torch.cat([negative, neg.unsqueeze(-1)], 1)\n",
    "\n",
    "\n",
    "\n",
    "        # mu_1 = mu.unsqueeze(1)          # [nsample,1,dim]\n",
    "        # logvar_1 = logvar.unsqueeze(1)\n",
    "        # y_samples_1 = y_samples.unsqueeze(0)            # [1,nsample,dim]\n",
    "        # all_probs =  (- (y_samples_1 - mu_1)**2/2./logvar_1.exp()- logvar_1/2.).sum(dim = -1)  #[nsample, nsample]\n",
    "\n",
    "        # diag_mask =  torch.ones([batch_size]).diag().unsqueeze(-1).cuda() * (-20.)\n",
    "        # negative = log_sum_exp(all_probs + diag_mask,dim=0) - np.log(batch_size-1.) #[nsample]\n",
    "        #print(( positive.unsqueeze(-1)- negative ).mean())\n",
    "       \n",
    "        return ( positive.unsqueeze(-1)- negative ).mean()\n",
    "    \n",
    "    def loglikeli(self, x_samples, y_samples):\n",
    "        x_samples = x_samples.clone()\n",
    "        y_samples = y_samples.clone()\n",
    "        mu, logvar = self.get_mu_logvar(x_samples)\n",
    "\n",
    "        lg = (-(mu - y_samples)**2 /logvar.exp()-logvar).sum(dim=1).mean(dim=0)\n",
    "\n",
    "        del x_samples, y_samples\n",
    "        torch.cuda.empty_cache()\n",
    "        #print(\"lg\", lg)\n",
    "        return lg\n",
    "    \n",
    "    def loglikeli_mask(self, x_samples, y_samples):\n",
    "        negative = []\n",
    "        x_samples = x_samples.clone()\n",
    "        y_samples = y_samples.clone()\n",
    "        for i in range(x_samples.shape[1]-1):\n",
    "            result = []\n",
    "        \n",
    "            for j in range(x_samples.shape[1]): \n",
    "                if j != i:\n",
    "                    result.append(j)\n",
    "            x_temp = torch.index_select(x_samples, dim=1, index=torch.tensor(result).cuda())\n",
    "            #x_temp = x_samples.index_fill_(1, torch.tensor([i]).cuda(), float('0'))\n",
    "            mu, logvar = self.get_mu_logvar_neg(x_temp)\n",
    "            neg =  (-(mu - y_samples)**2 /logvar.exp()-logvar).sum(dim=-1) #(- (mu - y_samples)**2 /2./logvar.exp() - logvar/2.).sum(dim = -1) #[nsample]\n",
    "            if i == 0:\n",
    "                negative = neg.unsqueeze(-1)\n",
    "            else:\n",
    "                negative = torch.cat([negative, neg.unsqueeze(-1)], 1)\n",
    "        del x_samples, y_samples\n",
    "        torch.cuda.empty_cache()\n",
    "        #print('mask', negative.sum(dim=1).mean(dim=0))\n",
    "        return negative.sum(dim=1).mean(dim=0)\n",
    "\n",
    "    def learning_loss(self, x_samples, y_samples):\n",
    "        return  - self.loglikeli_mask(x_samples, y_samples)  - self.loglikeli(x_samples, y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim = 5\n",
    "dataset = CMINE.create_dataset_DGP(GenModel=\"\", Params=\"\", Dim=5, N=64)\n",
    "s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "a = torch.from_numpy(dataset[2]).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_next.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 11])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([s_t,a], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.55458068847656\n",
      "-9.276410102844238\n",
      "62.727333068847656\n",
      "-25.810632705688477\n",
      "0.3335517942905426\n",
      "-7.680867671966553\n",
      "-34.82990646362305\n",
      "-0.19748543202877045\n",
      "16.214752197265625\n",
      "-4.186553955078125\n",
      "-1.5425317287445068\n",
      "-16.854326248168945\n",
      "2.8642261028289795\n",
      "0.9347788095474243\n",
      "-0.3923979103565216\n",
      "-25.0108699798584\n",
      "31.083845138549805\n",
      "1400.1199951171875\n",
      "1.8318172693252563\n",
      "6840.84521484375\n",
      "151.7137451171875\n",
      "-334.0803527832031\n",
      "22.699750900268555\n",
      "2.9017765522003174\n",
      "-67.77193450927734\n",
      "-57.051727294921875\n",
      "24.697229385375977\n",
      "-3.0523264408111572\n",
      "2420.28759765625\n",
      "-7.352047920227051\n",
      "1434.9871826171875\n",
      "-13.111729621887207\n",
      "-253.88023376464844\n",
      "156188.984375\n",
      "0.21841326355934143\n",
      "7.732656002044678\n",
      "0.4668305516242981\n",
      "-48112928.0\n",
      "1.1738598346710205\n",
      "-10.919944763183594\n",
      "-3.241413116455078\n",
      "-14.684198379516602\n",
      "-3.191225051879883\n",
      "4384.7978515625\n",
      "2.213449239730835\n",
      "72.15056610107422\n",
      "-2.7987749576568604\n",
      "1.6570396423339844\n",
      "-274302.28125\n",
      "-0.7642926573753357\n",
      "-118.3180923461914\n",
      "1.8192790746688843\n",
      "-1395826.625\n",
      "-126.4516372680664\n",
      "-942.90673828125\n",
      "284423.75\n",
      "0.10621768236160278\n",
      "-13.643109321594238\n",
      "0.2834753096103668\n",
      "-1.3612302541732788\n",
      "50.225887298583984\n",
      "15.627275466918945\n",
      "-12.01474666595459\n",
      "-120.81623840332031\n",
      "-64.45818328857422\n",
      "-21.15156364440918\n",
      "-5.176771640777588\n",
      "-142.990478515625\n",
      "0.6954679489135742\n",
      "-12559.3505859375\n",
      "-7.579322814941406\n",
      "-0.6436579823493958\n",
      "146.5840301513672\n",
      "3.95505690574646\n",
      "-6.030571460723877\n",
      "1.2617086172103882\n",
      "-83.37409973144531\n",
      "-4.825048923492432\n",
      "-6.576902866363525\n",
      "4.258295059204102\n",
      "90.46073913574219\n",
      "-65.12470245361328\n",
      "-0.11306271702051163\n",
      "3247564544.0\n",
      "-1.2891355752944946\n",
      "-2.672933340072632\n",
      "-3.2340009212493896\n",
      "0.007878461852669716\n",
      "622209.1875\n",
      "-204942.359375\n",
      "-0.43613967299461365\n",
      "-0.3401033878326416\n",
      "-0.2844866216182709\n",
      "-220.6201171875\n",
      "1557.2249755859375\n",
      "-718164608.0\n",
      "652.9088745117188\n",
      "-2.2936339378356934\n",
      "-40.99579620361328\n",
      "-127.93144989013672\n",
      "-1.4217294454574585\n",
      "1391.7679443359375\n",
      "-61.400123596191406\n",
      "-0.3606320321559906\n",
      "-4.241098403930664\n",
      "-7238.50634765625\n",
      "-0.40128904581069946\n",
      "-2687643.25\n",
      "736.1071166992188\n",
      "0.7437017560005188\n",
      "-4.729711055755615\n",
      "-0.31237277388572693\n",
      "-190.71153259277344\n",
      "-0.10475709289312363\n",
      "-0.04874805733561516\n",
      "0.1481434404850006\n",
      "-33.71255874633789\n",
      "379010.71875\n",
      "-2.628541946411133\n",
      "-1.5642658472061157\n",
      "-4.590730667114258\n",
      "-1.083558440208435\n",
      "-37645024.0\n",
      "-1.7991294860839844\n",
      "35.774169921875\n",
      "143.81741333007812\n",
      "123.203369140625\n",
      "1.162432312965393\n",
      "-3.534108877182007\n",
      "-41.093692779541016\n",
      "-53.824092864990234\n",
      "-1.6688343286514282\n",
      "-1.1272932291030884\n",
      "234.06875610351562\n",
      "-1.495835304260254\n",
      "-6.625552654266357\n",
      "-433.4566955566406\n",
      "-27.144561767578125\n",
      "-1.3308571577072144\n",
      "0.28710901737213135\n",
      "-26.031681060791016\n",
      "-83.14241027832031\n",
      "157.6008758544922\n",
      "-953.2076416015625\n",
      "-174.3268280029297\n",
      "-36.96085739135742\n",
      "-40.52816390991211\n",
      "-1.8488491773605347\n",
      "-26427.685546875\n",
      "-58.52387237548828\n",
      "235941.203125\n",
      "-134.43399047851562\n",
      "-2.4726407527923584\n",
      "3929.450439453125\n",
      "-2.8031041622161865\n",
      "-2.9922397136688232\n",
      "-0.73818439245224\n",
      "-67.90733337402344\n",
      "-7.440492153167725\n",
      "-36.222564697265625\n",
      "-38.71849822998047\n",
      "-1.3598928451538086\n",
      "-1.696295976638794\n",
      "-50.318660736083984\n",
      "0.22442631423473358\n",
      "-2.6720128059387207\n",
      "-1206.5751953125\n",
      "-0.8847057223320007\n",
      "109.817138671875\n",
      "-0.4010131061077118\n",
      "-7.077322483062744\n",
      "-2.7636168003082275\n",
      "-9.000680923461914\n",
      "-243.4101104736328\n",
      "-4.18649959564209\n",
      "-2.79990553855896\n",
      "-79.04652404785156\n",
      "-54.800289154052734\n",
      "-12.104994773864746\n",
      "-5.821258068084717\n",
      "65.41654205322266\n",
      "-28.8863468170166\n",
      "-9.775156021118164\n",
      "-62.177772521972656\n",
      "-1.655892252922058\n",
      "-2.7446951866149902\n",
      "-33.53916931152344\n",
      "-20.835607528686523\n",
      "-2.809915542602539\n",
      "-2.2044448852539062\n",
      "0.7210465669631958\n",
      "-0.3190474212169647\n",
      "-0.009406312368810177\n",
      "58.71184158325195\n",
      "-297.02618408203125\n",
      "-45.568565368652344\n",
      "-10.792869567871094\n",
      "51.62411117553711\n",
      "7372.8955078125\n",
      "-9.179681777954102\n",
      "122.3979263305664\n",
      "557.5471801757812\n",
      "-0.9395372271537781\n",
      "1.1566333770751953\n",
      "1922110.375\n",
      "-2.5330867767333984\n",
      "-686.4689331054688\n",
      "-0.4264199435710907\n",
      "177.9047088623047\n",
      "4688.2353515625\n",
      "0.6864882707595825\n",
      "1.9606541395187378\n",
      "-20.862680435180664\n",
      "30874438.0\n",
      "-41060076.0\n",
      "-41.01526641845703\n",
      "-19.587121963500977\n",
      "-82.04088592529297\n",
      "-4.934792518615723\n",
      "-2.2131292819976807\n",
      "34.5578727722168\n",
      "-6.9013991355896\n",
      "0.6179293990135193\n",
      "2.8762924671173096\n",
      "-3.5376622676849365\n",
      "-2.157036066055298\n",
      "0.8966028094291687\n",
      "-0.7850975394248962\n",
      "-5.43534517288208\n",
      "-13.100865364074707\n",
      "-0.30029407143592834\n",
      "2.738163948059082\n",
      "139.1659698486328\n",
      "12671.9013671875\n",
      "6.721015930175781\n",
      "36.643951416015625\n",
      "533138272.0\n",
      "-577.82177734375\n",
      "-1.6497697830200195\n",
      "1.1721246242523193\n",
      "-921.1613159179688\n",
      "-1461.3004150390625\n",
      "-6.851897716522217\n",
      "1.3379234075546265\n",
      "6.9229936599731445\n",
      "0.04913885146379471\n",
      "139.35691833496094\n",
      "-1007.1570434570312\n",
      "22.323225021362305\n",
      "-2.313196897506714\n",
      "377.5668640136719\n",
      "0.18102064728736877\n",
      "-0.8725113272666931\n",
      "1.3630441427230835\n",
      "-3.7307217121124268\n",
      "-8.622221946716309\n",
      "-48.5012092590332\n",
      "0.4060707986354828\n",
      "-0.3831903636455536\n",
      "-8.97508716583252\n",
      "-1.0452107191085815\n",
      "-69467.7265625\n",
      "131.3606414794922\n",
      "0.2527500092983246\n",
      "-262.8506774902344\n",
      "0.484852135181427\n",
      "-4.778287410736084\n",
      "2.078382730484009\n",
      "4.641273021697998\n",
      "-0.34075894951820374\n",
      "0.496054083108902\n",
      "-1.688719630241394\n",
      "0.8689404726028442\n",
      "17.35207176208496\n",
      "-15.156353950500488\n",
      "-0.32539916038513184\n",
      "-2.6421172618865967\n",
      "-29.47222900390625\n",
      "-0.23303547501564026\n",
      "-18.03453826904297\n",
      "-2.0396676063537598\n",
      "-2.784518003463745\n",
      "-9.403656005859375\n",
      "-388.2806091308594\n",
      "-11.600631713867188\n",
      "-33.69649887084961\n",
      "0.2683574855327606\n",
      "-6.7640204429626465\n",
      "0.49224892258644104\n",
      "-0.7819564938545227\n",
      "3120.12744140625\n",
      "14.463090896606445\n",
      "-5.19695520401001\n",
      "-885.64013671875\n",
      "-0.07188651710748672\n",
      "-1.7089229822158813\n",
      "532607.75\n",
      "11.16326904296875\n",
      "-3.4644463062286377\n",
      "170.7294158935547\n",
      "0.927647054195404\n",
      "0.5511550903320312\n",
      "0.48090019822120667\n",
      "-2.1617753505706787\n",
      "2.7879483699798584\n",
      "-0.16830454766750336\n",
      "-98.98624420166016\n",
      "-0.6973849534988403\n",
      "15.685661315917969\n",
      "1.1073709726333618\n",
      "118.42066955566406\n",
      "-100.77843475341797\n",
      "-1.510934829711914\n",
      "1.5899946689605713\n",
      "-135.9578094482422\n",
      "-4.08552360534668\n",
      "-7.966407299041748\n",
      "-1.3610233068466187\n",
      "0.9151420593261719\n",
      "-11.677313804626465\n",
      "0.2751380503177643\n",
      "-37.288143157958984\n",
      "-15.068338394165039\n",
      "-0.7534856796264648\n",
      "1.064806342124939\n",
      "-0.04931953549385071\n",
      "25.44364356994629\n",
      "0.9374818801879883\n",
      "0.7923516035079956\n",
      "6.6921706199646\n",
      "3.5769288539886475\n",
      "-4.985194683074951\n",
      "-2.0444653034210205\n",
      "-3.2741525173187256\n",
      "-10.021696090698242\n",
      "5.437610626220703\n",
      "-0.22160296142101288\n",
      "-8.525832176208496\n",
      "-101.06671142578125\n",
      "-52.08221435546875\n",
      "-25503.33203125\n",
      "-826.6488647460938\n",
      "-5.982363700866699\n",
      "-15808.158203125\n",
      "67.30614471435547\n",
      "12.622820854187012\n",
      "10259.3427734375\n",
      "-3.251934051513672\n",
      "10.956244468688965\n",
      "16.74979019165039\n",
      "-3.652637481689453\n",
      "-98.3117904663086\n",
      "34.558475494384766\n",
      "-8.393959999084473\n",
      "-48.7658576965332\n",
      "0.13920187950134277\n",
      "-13.0424222946167\n",
      "173.6941375732422\n",
      "957.9537353515625\n",
      "-0.46444687247276306\n",
      "0.8735818266868591\n",
      "-45.22962188720703\n",
      "6.278881072998047\n",
      "4.044994354248047\n",
      "43.23592758178711\n",
      "0.834674060344696\n",
      "-155.91636657714844\n",
      "1.3936114311218262\n",
      "-1536.2918701171875\n",
      "-2.6895532608032227\n",
      "652.9387817382812\n",
      "14.679709434509277\n",
      "194.7942657470703\n",
      "-0.686896562576294\n",
      "3.4572513103485107\n",
      "20.77802085876465\n",
      "-2.8544209003448486\n",
      "8.031950950622559\n",
      "-0.011013722978532314\n",
      "0.3754580020904541\n",
      "-65.2613525390625\n",
      "0.10822924226522446\n",
      "-13.198225975036621\n",
      "7.649560451507568\n",
      "-107.44634246826172\n",
      "1.2591804265975952\n",
      "-0.20709431171417236\n",
      "139.7571258544922\n",
      "-1558.8448486328125\n",
      "564681.3125\n",
      "1.0448483228683472\n",
      "2.440885543823242\n",
      "-183.7555389404297\n",
      "1134.3131103515625\n",
      "-25.390493392944336\n",
      "21.93024444580078\n",
      "-0.7549037933349609\n",
      "-0.4376423954963684\n",
      "1.6274198293685913\n",
      "-155.81393432617188\n",
      "3.912989377975464\n",
      "-2.3322579860687256\n",
      "-1.2236360311508179\n",
      "-20.46344566345215\n",
      "-4.35591983795166\n",
      "0.7236905097961426\n",
      "1.5240496397018433\n",
      "0.605776309967041\n",
      "0.7237688899040222\n",
      "-2.878385305404663\n",
      "-98.2247543334961\n",
      "-56.93745803833008\n",
      "-2.067049741744995\n",
      "-4.156400680541992\n",
      "1.2842824459075928\n",
      "-1405.4761962890625\n",
      "-132.7596893310547\n",
      "25.04477310180664\n",
      "2.4509708881378174\n",
      "-0.07872267067432404\n",
      "-0.5129110217094421\n",
      "-28.08993911743164\n",
      "-1.1466975212097168\n",
      "-0.02441192977130413\n",
      "-3.3333489894866943\n",
      "-37.384437561035156\n",
      "93.3272933959961\n",
      "0.6046895384788513\n",
      "-0.8661872744560242\n",
      "518073.25\n",
      "0.23409023880958557\n",
      "0.010090338066220284\n",
      "-13.820779800415039\n",
      "-7.181924343109131\n",
      "-1.196398377418518\n",
      "1861.1649169921875\n",
      "-53.67275619506836\n",
      "-17.429677963256836\n",
      "-1.7870296239852905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.107605934143066\n",
      "151.75003051757812\n",
      "1326.2083740234375\n",
      "-299.0632629394531\n",
      "-236.990478515625\n",
      "-15.88261604309082\n",
      "-100.58842468261719\n",
      "4.0411553382873535\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_890/1015638452.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCMINE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset_DGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGenModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0ms_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meladyfs/newyork/defucao/NeurIPS2023/CMI_Neural_Estimator_DGP/CDL_estimation/CMINE_lib.py\u001b[0m in \u001b[0;36mcreate_dataset_DGP\u001b[0;34m(GenModel, Params, Dim, N, T)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# [X_, Endo_, Rx_, Re_, R, A_] = exo_endo_mdp_linear(MDP_info, T, policy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mN_traj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mX__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndo__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRx__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRe__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_trajectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_traj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexo_endo_mdp_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMDP_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;31m# (S_t,A_t, R_t,S_{t+1}) tuples for t = 1,T-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mStA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndo__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meladyfs/newyork/defucao/NeurIPS2023/CMI_Neural_Estimator_DGP/CDL_estimation/structurerl.py\u001b[0m in \u001b[0;36mget_trajectories\u001b[0;34m(N_traj, env, MDP_info, T, policy)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mA__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN_traj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_A\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_traj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndo_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRe_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMDP_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mX__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mEndo__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEndo_\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mRx__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRx_\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mRe__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRe_\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mA__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndo__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRx__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRe__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meladyfs/newyork/defucao/NeurIPS2023/CMI_Neural_Estimator_DGP/CDL_estimation/structurerl.py\u001b[0m in \u001b[0;36mexo_endo_mdp_linear\u001b[0;34m(MDP_info, T, policy)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mEndo_t1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMendo\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEndo_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_endo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.04\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mRxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.09\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mRet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndo_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEndo_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#np.exp(-np.log(np.abs(np.mean(Endo_t) - 1)) )+ np.random.normal(loc=0, scale=0.03)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mX__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_t1\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mEndo__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEndo_t1\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mRx__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRxt\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mRe__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "sample_dim = 2*Dim\n",
    "batch_size = 64\n",
    "hidden_size = 15\n",
    "learning_rate = 0.005\n",
    "training_steps = 4000\n",
    "\n",
    "cubic = False \n",
    "\n",
    "# %%\n",
    "model = L1OutUB(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "mi_est_values = []\n",
    "\n",
    "# %%\n",
    "for step in range(training_steps):\n",
    "    #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "    dataset = CMINE.create_dataset_DGP(GenModel=\"\", Params=\"\", Dim=5, N=64)\n",
    "    s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "    s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "    a = torch.from_numpy(dataset[2]).float().cuda()\n",
    "    \n",
    "    batch_x = torch.cat([s_t,a], dim=1)\n",
    "    batch_y = s_next\n",
    "    model.eval()\n",
    "    cmi = model(batch_x, batch_y).item()\n",
    "    mi_est_values.append(cmi)\n",
    "    #print(cmi)\n",
    "    # %%\n",
    "    model.train() \n",
    "\n",
    "    model_loss = model.learning_loss(batch_x, batch_y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    model_loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    del batch_x, batch_y\n",
    "    torch.cuda.empty_cache()\n",
    "#print(\"finish training for %s with true MI value = %f\"%('LOO', 6.0))\n",
    "print(np.array(mi_est_values).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffscm_gpu",
   "language": "python",
   "name": "diffscm_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
