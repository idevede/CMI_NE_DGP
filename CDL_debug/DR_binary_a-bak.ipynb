{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy.linalg import det\n",
    "\n",
    "import CMINE_lib as CMINE\n",
    "# from Guassian_variables import Data_guassian\n",
    "from structurerl import * \n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import itertools\n",
    "\n",
    "np.random.seed(37)\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import math\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(value, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable implementation of the operation\n",
    "    value.exp().sum(dim, keepdim).log()\n",
    "    \"\"\"\n",
    "    # TODO: torch.max(value, dim=None) threw an error at time of writing\n",
    "    if dim is not None:\n",
    "        m, _ = torch.max(value, dim=dim, keepdim=True)\n",
    "        value0 = value - m\n",
    "        if keepdim is False:\n",
    "            m = m.squeeze(dim)\n",
    "        return m + torch.log(torch.sum(torch.exp(value0),\n",
    "                                       dim=dim, keepdim=keepdim))\n",
    "    else:\n",
    "        m = torch.max(value)\n",
    "        sum_exp = torch.sum(torch.exp(value - m))\n",
    "        if isinstance(sum_exp, Number):\n",
    "            return m + math.log(sum_exp)\n",
    "        else:\n",
    "            return m + torch.log(sum_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.CMI import DR_CMI, CDL_CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim = 5\n",
    "batch_size = 64\n",
    "#dataset = CMINE.create_dataset_DGP( Dim=5, N=batch_size)\n",
    "dataset = create_dataset_DGP_binary_A_conf( Dim=5, N=batch_size)\n",
    "s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "a = torch.from_numpy(dataset[2]).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dim = 2*Dim\n",
    "\n",
    "hidden_size = 15\n",
    "learning_rate = 0.005\n",
    "training_steps = 10\n",
    "\n",
    "cubic = False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dr(N = 64, training_steps = 10):\n",
    "    torch.cuda.empty_cache()\n",
    "    model_dr = DR_CMI(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "    optimizer_dr = torch.optim.Adam(model_dr.parameters(), learning_rate)\n",
    "    dr_est_values = []\n",
    "    for step in range(training_steps):\n",
    "        #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "        dataset = create_dataset_DGP_binary_A_conf(Dim=Dim, N=N)\n",
    "        #dataset = create_dataset_DGP_binary_A(Dim=Dim, N=N)\n",
    "        s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "        s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "        a = torch.from_numpy(dataset[2]).float().cuda()\n",
    "        #print(a)\n",
    "\n",
    "        batch_x = torch.cat([s_t,a], dim=1)\n",
    "        batch_y = s_next\n",
    "        model_dr.eval()\n",
    "        drs = model_dr(batch_x, batch_y)\n",
    "        #mi_est_values.append(cmi)\n",
    "        dr_est_values.append(drs)\n",
    "        model_dr.train() \n",
    "\n",
    "        model_loss = model_dr.learning_loss(batch_x, batch_y)\n",
    "\n",
    "        optimizer_dr.zero_grad()\n",
    "        model_loss.backward(retain_graph=True)\n",
    "        optimizer_dr.step()\n",
    "\n",
    "        del batch_x, batch_y\n",
    "        torch.cuda.empty_cache()\n",
    "    return dr_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cdl(N = 64, training_steps = 10):\n",
    "    torch.cuda.empty_cache()\n",
    "    model_cdl = CDL_CMI(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "    optimizer_cdl = torch.optim.Adam(model_cdl.parameters(), learning_rate)\n",
    "    cdl_est_values = []\n",
    "    for step in range(training_steps):\n",
    "        #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "        dataset = create_dataset_DGP_binary_A_conf(Dim=Dim, N=64)\n",
    "        s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "        s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "        a = torch.from_numpy(dataset[2]).float().cuda()\n",
    "\n",
    "        batch_x = torch.cat([s_t,a], dim=1)\n",
    "        batch_y = s_next\n",
    "        model_cdl.eval()\n",
    "        cdl_cmi = model_cdl(batch_x, batch_y)\n",
    "        cdl_est_values.append(cdl_cmi)\n",
    "        model_cdl.train() \n",
    "\n",
    "        model_loss = model_cdl.learning_loss(batch_x, batch_y)\n",
    "\n",
    "        optimizer_cdl.zero_grad()\n",
    "        model_loss.backward(retain_graph=True)\n",
    "        optimizer_cdl.step()\n",
    "\n",
    "        del batch_x, batch_y\n",
    "        torch.cuda.empty_cache()\n",
    "    return cdl_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.55841162e-01 1.83366506e-01 7.63569712e-01 1.81353542e-01\n",
      " 1.91939004e+01 8.49449045e+01 1.08508483e+01 6.22935141e+01\n",
      " 5.90143340e+04 9.97852150e+02]\n",
      "[3.28495663e+00 1.92005296e+02 9.78379222e-01 9.20910714e-01\n",
      " 3.18418048e+00 1.40984777e+05 7.62842189e+00 1.08530980e+01\n",
      " 4.70197222e+02 5.52779821e+01]\n"
     ]
    }
   ],
   "source": [
    "N=16\n",
    "cdl_est_values = train_cdl(N)\n",
    "dr_est_values = train_dr(N)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.71821213e+03 3.92298965e+03 3.92560532e+03 4.07484497e+03\n",
      " 3.92057935e+03 1.81596002e+05 9.33726825e+04 3.76935484e+04\n",
      " 9.85317383e+07 2.06142556e+06]\n",
      "[4.63405831e+03 3.99647462e+03 3.83436325e+05 1.81859468e+03\n",
      " 1.49838548e+07 1.83382114e+02 4.27130462e+05 4.74919770e+01\n",
      " 4.08414217e+02 6.06603382e+01]\n"
     ]
    }
   ],
   "source": [
    "N = 128\n",
    "cdl_est_values = train_cdl(N)\n",
    "dr_est_values = train_dr(N)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.93015250e+01 1.93217939e+01 1.93001622e+01 1.95151818e+01\n",
      " 1.92402013e+01 2.59949862e+03 7.23254312e+04 4.48272244e+07\n",
      " 5.50522303e+03 7.26690101e+02]\n",
      "[6.97830773e+00 1.15795425e+04 3.91971305e+00 3.98680437e+00\n",
      " 3.74568180e+00 2.13246227e+02 1.83963891e+06 2.04545174e+05\n",
      " 3.31064171e+02 9.15712292e+03]\n"
     ]
    }
   ],
   "source": [
    "N = 32\n",
    "cdl_est_values = train_cdl(N)\n",
    "dr_est_values = train_dr(N)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58.36168671  0.61062402  3.47006393  0.20982889  1.38706867  0.33824272\n",
      "  0.22131474  1.47916541  0.23722787  2.16484535]\n",
      "[2.85136978e+01 1.37017854e+00 1.99884313e+01 7.38385294e+01\n",
      " 2.44119127e+02 6.53696296e+03 4.12326024e+04 1.20587470e+05\n",
      " 1.75584465e+06 2.07950426e+02]\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "cdl_est_values = train_cdl(N)\n",
    "dr_est_values = train_dr(N)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.31943605e+04 1.71830261e+08 6.60621143e+04 1.83854909e+05\n",
      " 6.29557521e+04 3.95083027e+09 5.30933075e+05 3.03847897e+05\n",
      " 3.01877772e+06 9.41156254e+05]\n",
      "[1.45674717e+05 5.62305784e+05 1.31564423e+05 1.34648689e+05\n",
      " 1.32427251e+06 2.39606343e+09 1.46911331e+14 6.66713691e+09\n",
      " 1.28531635e+08 2.40902858e+09]\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "training_step = 100\n",
    "cdl_est_values = train_cdl(N, training_step)\n",
    "dr_est_values = train_dr(N, training_step)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.68653295e+04 8.02705649e+00 1.19907736e+03 3.14780780e+01\n",
      " 3.98932782e+01 8.38730004e+05 3.92318122e+03 6.95953489e+04\n",
      " 1.22019822e+05 3.48546747e+06]\n",
      "[9.74688966e+03 7.74597234e+03 2.96815940e+09 6.31418542e+03\n",
      " 6.20089638e+03 1.22671743e+06 3.68697284e+09 4.77083438e+06\n",
      " 1.44713419e+07 1.88002237e+07]\n"
     ]
    }
   ],
   "source": [
    "N = 32\n",
    "training_step = 100\n",
    "cdl_est_values = train_cdl(N, training_step)\n",
    "dr_est_values = train_dr(N, training_step)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50006065e+01 2.18871596e+02 1.10105989e+07 5.11114454e+02\n",
      " 1.06051950e+02 9.00031509e+01 1.04145438e+04 3.52512225e+03\n",
      " 5.52125692e+03 2.41971664e+04]\n",
      "[7.68950225e+06 7.74432824e+06 7.91731634e+06 7.70377130e+06\n",
      " 7.70934032e+06 7.88427070e+08 4.68894041e+16 1.52884448e+10\n",
      " 1.34091251e+11 2.40433729e+10]\n"
     ]
    }
   ],
   "source": [
    "N = 526\n",
    "training_step = 100\n",
    "cdl_est_values = train_cdl(N, training_step)\n",
    "dr_est_values = train_dr(N, training_step)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.41623130e-01 5.83663910e-01 2.62432172e-01 1.86141613e-01\n",
      " 2.88988191e+02 2.00060656e+01 5.57397880e+00 2.69901884e+01\n",
      " 2.13138771e-01 1.53580540e+00]\n",
      "[1.34774063e+06 7.49846064e+03 7.87508115e+03 7.57209025e+03\n",
      " 7.50388969e+03 5.57463735e+05 1.85607135e+04 3.51530271e+09\n",
      " 1.84042864e+05 2.73516473e+06]\n"
     ]
    }
   ],
   "source": [
    "N = 526\n",
    "training_step = 10\n",
    "cdl_est_values = train_cdl(N, training_step)\n",
    "dr_est_values = train_dr(N, training_step)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffscm_gpu",
   "language": "python",
   "name": "diffscm_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
