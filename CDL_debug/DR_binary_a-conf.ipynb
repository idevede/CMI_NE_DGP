{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy.linalg import det\n",
    "\n",
    "import CMINE_lib as CMINE\n",
    "# from Guassian_variables import Data_guassian\n",
    "from structurerl import * \n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import itertools\n",
    "\n",
    "np.random.seed(37)\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import math\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(value, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable implementation of the operation\n",
    "    value.exp().sum(dim, keepdim).log()\n",
    "    \"\"\"\n",
    "    # TODO: torch.max(value, dim=None) threw an error at time of writing\n",
    "    if dim is not None:\n",
    "        m, _ = torch.max(value, dim=dim, keepdim=True)\n",
    "        value0 = value - m\n",
    "        if keepdim is False:\n",
    "            m = m.squeeze(dim)\n",
    "        return m + torch.log(torch.sum(torch.exp(value0),\n",
    "                                       dim=dim, keepdim=keepdim))\n",
    "    else:\n",
    "        m = torch.max(value)\n",
    "        sum_exp = torch.sum(torch.exp(value - m))\n",
    "        if isinstance(sum_exp, Number):\n",
    "            return m + math.log(sum_exp)\n",
    "        else:\n",
    "            return m + torch.log(sum_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.CMI import DR_CMI, CDL_CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim = 5\n",
    "batch_size = 64\n",
    "#dataset = CMINE.create_dataset_DGP( Dim=5, N=batch_size)\n",
    "dataset = create_dataset_DGP_binary_A_conf( Dim=5, N=batch_size)\n",
    "s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "a = torch.from_numpy(dataset[2]).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dim = 2*Dim\n",
    "\n",
    "hidden_size = 15\n",
    "learning_rate = 0.005\n",
    "training_steps = 10\n",
    "\n",
    "cubic = False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dr(N = 64, training_steps = 10):\n",
    "    torch.cuda.empty_cache()\n",
    "    model_dr = DR_CMI(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "    optimizer_dr = torch.optim.Adam(model_dr.parameters(), learning_rate)\n",
    "    dr_est_values = []\n",
    "    for step in range(training_steps):\n",
    "        #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "        dataset = create_dataset_DGP_binary_A_conf(Dim=Dim, N=N)\n",
    "        #dataset = create_dataset_DGP_binary_A(Dim=Dim, N=N)\n",
    "        s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "        s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "        a = torch.from_numpy(dataset[2]).float().cuda()\n",
    "        #print(a)\n",
    "\n",
    "        batch_x = torch.cat([s_t,a], dim=1)\n",
    "        batch_y = s_next\n",
    "        model_dr.eval()\n",
    "        drs = model_dr(batch_x, batch_y)\n",
    "        #mi_est_values.append(cmi)\n",
    "        dr_est_values.append(drs)\n",
    "        model_dr.train() \n",
    "\n",
    "        model_loss = model_dr.learning_loss(batch_x, batch_y)\n",
    "\n",
    "        optimizer_dr.zero_grad()\n",
    "        model_loss.backward(retain_graph=True)\n",
    "        optimizer_dr.step()\n",
    "\n",
    "        del batch_x, batch_y\n",
    "        torch.cuda.empty_cache()\n",
    "    return dr_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cdl(N = 64, training_steps = 10):\n",
    "    torch.cuda.empty_cache()\n",
    "    model_cdl = CDL_CMI(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "    optimizer_cdl = torch.optim.Adam(model_cdl.parameters(), learning_rate)\n",
    "    cdl_est_values = []\n",
    "    for step in range(training_steps):\n",
    "        #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "        dataset = create_dataset_DGP_binary_A_conf(Dim=Dim, N=N)\n",
    "        #dataset = create_dataset_DGP_binary_A(Dim=Dim, N=64)\n",
    "        s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "        s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "        a = torch.from_numpy(dataset[2]).float().cuda()\n",
    "\n",
    "        batch_x = torch.cat([s_t,a], dim=1)\n",
    "        batch_y = s_next\n",
    "        model_cdl.eval()\n",
    "        cdl_cmi = model_cdl(batch_x, batch_y)\n",
    "        cdl_est_values.append(cdl_cmi)\n",
    "        model_cdl.train() \n",
    "\n",
    "        model_loss = model_cdl.learning_loss(batch_x, batch_y)\n",
    "\n",
    "        optimizer_cdl.zero_grad()\n",
    "        model_loss.backward(retain_graph=True)\n",
    "        optimizer_cdl.step()\n",
    "\n",
    "        del batch_x, batch_y\n",
    "        torch.cuda.empty_cache()\n",
    "    return cdl_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.66903359e-01 3.78592699e-01 1.09443370e+00 3.73501374e-01\n",
      " 2.49644741e+01 1.00996595e+02 1.15010062e+01 9.64416630e+01\n",
      " 4.71799744e+04 1.12813400e+03]\n",
      "[8.61506927e+00 5.34268573e+02 7.79979905e+00 7.74187610e+00\n",
      " 2.01804693e+01 9.33145221e+01 2.62178414e+03 8.34404091e+06\n",
      " 4.12179292e+04 3.11120993e+03]\n"
     ]
    }
   ],
   "source": [
    "N=64\n",
    "cdl_est_values = train_cdl(N, 10)\n",
    "dr_est_values = train_dr(N, 10)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50636170e-01 2.51828551e-01 3.41618330e-01 8.13286927e-01\n",
      " 1.84991731e-01 1.35610701e+01 1.30043054e+02 1.02664226e+03\n",
      " 3.00127399e+00 1.18379684e+01]\n",
      "[4.34859016e+00 5.12984808e+00 3.97684840e+00 3.75351808e+00\n",
      " 3.78433738e+00 1.29759883e+03 2.61710395e+03 2.93950363e+06\n",
      " 3.11723659e+06 3.26061075e+04]\n"
     ]
    }
   ],
   "source": [
    "N=128\n",
    "cdl_est_values = train_cdl(N, 10)\n",
    "dr_est_values = train_dr(N, 10)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 32\n",
    "cdl_est_values = train_cdl(N, 10)\n",
    "dr_est_values = train_dr(N, 10)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "cdl_est_values = train_cdl(N, 10)\n",
    "dr_est_values = train_dr(N, 10)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "cdl_est_values = train_cdl(N, 10)\n",
    "dr_est_values = train_dr(N, 10)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "cdl_est_values = train_cdl(N, 100)\n",
    "dr_est_values = train_dr(N, 100)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_esm(N = 64, training_steps = 10, noise = 0.1):\n",
    "    torch.cuda.empty_cache()\n",
    "    model_dr = DR_CMI(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "    optimizer_dr = torch.optim.Adam(model_dr.parameters(), learning_rate)\n",
    "    dr_est_values = []\n",
    "    \n",
    "    model_cdl = CDL_CMI(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "    optimizer_cdl = torch.optim.Adam(model_cdl.parameters(), learning_rate)\n",
    "    cdl_est_values = []\n",
    "    \n",
    "    for step in range(training_steps):\n",
    "        #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "        #dataset = create_dataset_DGP_binary_A_more_noise(Dim=Dim, N=N, noise = noise)\n",
    "        dataset = create_dataset_DGP_binary_A_conf(Dim=Dim, N=N)\n",
    "        s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "        s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "        a = torch.from_numpy(dataset[2]).float().cuda()\n",
    "\n",
    "        batch_x = torch.cat([s_t,a], dim=1)\n",
    "        batch_y = s_next\n",
    "        model_dr.eval()\n",
    "        drs = model_dr(batch_x, batch_y)\n",
    "        #mi_est_values.append(cmi)\n",
    "        dr_est_values.append(drs)\n",
    "        model_dr.train() \n",
    "\n",
    "        model_loss = model_dr.learning_loss(batch_x, batch_y)\n",
    "\n",
    "        optimizer_dr.zero_grad()\n",
    "        model_loss.backward(retain_graph=True)\n",
    "        optimizer_dr.step()\n",
    "        \n",
    "        model_cdl.eval()\n",
    "        cdl_cmi = model_cdl(batch_x, batch_y)\n",
    "        cdl_est_values.append(cdl_cmi)\n",
    "        model_cdl.train() \n",
    "\n",
    "        model_loss = model_cdl.learning_loss(batch_x, batch_y)\n",
    "\n",
    "        optimizer_cdl.zero_grad()\n",
    "        model_loss.backward(retain_graph=True)\n",
    "        optimizer_cdl.step()\n",
    "\n",
    "\n",
    "        del batch_x, batch_y\n",
    "        torch.cuda.empty_cache()\n",
    "    return dr_est_values, cdl_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.31547842e+01 1.73280756e-01 1.17183995e-01 1.82330843e+00\n",
      " 2.07884861e-01 2.23116390e-01 7.78402554e+02 7.33982662e-01\n",
      " 8.02943257e-01 1.03628662e+01]\n",
      "[1.89929298e+01 2.66419522e-01 1.94221662e-01 2.45989381e+00\n",
      " 2.87373597e-01 6.21806954e-01 2.70172439e+03 1.87946417e+00\n",
      " 3.61373760e+00 4.22714500e+01]\n",
      "----------8----------\n",
      "[0.06898578 0.10982551 0.2617607  0.40477213 0.0435957  2.14088626\n",
      " 0.73436396 0.77330426 0.37491311 0.23698735]\n",
      "[0.08910666 0.07416968 0.40184182 1.48501316 0.11630445 0.46499816\n",
      " 1.30036904 0.69127049 0.4901029  0.18706291]\n",
      "----------16----------\n",
      "[1.86766602e-01 9.64338481e-02 1.97127333e-01 1.23148128e-01\n",
      " 1.89800043e+00 1.94825692e+01 3.57280501e+01 3.03296854e-01\n",
      " 1.58314360e+03 2.94712819e+02]\n",
      "[2.39874109e-02 3.08062576e-02 2.64425001e-01 3.90342452e-02\n",
      " 6.42456384e-01 8.52548457e+00 4.79466914e+00 1.19641209e-01\n",
      " 3.05708110e+02 4.41885638e+01]\n",
      "----------32----------\n",
      "[3.07536560e+00 2.76674908e-01 1.80680092e-01 1.83713320e-01\n",
      " 1.76113516e-01 2.68694019e+00 9.35463018e-01 3.73349895e+01\n",
      " 6.47760898e+03 7.05350791e+01]\n",
      "[9.56017338e-01 7.27845169e-02 2.56807772e-02 2.58886856e-02\n",
      " 3.09393238e-02 6.39248314e-01 2.22144965e+00 6.96605110e+01\n",
      " 5.30886167e+02 1.37133408e+02]\n",
      "----------64----------\n",
      "[2.42537296e-01 2.38824968e-01 5.41924406e-01 4.89487609e+00\n",
      " 5.91933309e-01 1.58334846e+01 3.15556941e+01 3.64703278e+01\n",
      " 1.84967387e+04 3.56590700e+00]\n",
      "[7.58557233e-01 7.68577860e-01 8.98530753e-01 2.90176336e+00\n",
      " 9.97853386e-01 3.11884889e+02 1.50393291e+02 8.85514030e+02\n",
      " 3.87190066e+05 1.97174794e+00]\n",
      "----------128----------\n"
     ]
    }
   ],
   "source": [
    "for N in [8, 16, 32, 64, 128]:\n",
    "    dr_est_values, cdl_est_values = train_esm(N, 10)\n",
    "    print(np.array(cdl_est_values).mean(axis=0))\n",
    "    print(np.array(dr_est_values).mean(axis=0))\n",
    "    print(\"--\"*5 + str(N)+\"--\"*5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.86353708e+02 2.79077705e+01 8.41839690e+01 8.36915318e-01\n",
      " 1.78719174e+01 1.01420350e+03 5.12897903e+00 9.98290751e+01\n",
      " 9.79660652e+01 6.48419108e+00]\n",
      "[4.84332749e+02 3.12275785e+01 5.32818646e+01 9.99005201e-01\n",
      " 1.63977099e+01 7.80220060e+03 2.64307278e+00 2.63723593e+02\n",
      " 2.71248675e+02 1.39402335e+01]\n",
      "----------8----------\n",
      "[2.56413789e+02 2.31900303e+01 3.37180200e+04 1.00431359e+01\n",
      " 3.14599085e+00 1.72148926e+05 6.55660335e+02 2.67861362e+04\n",
      " 4.50546014e+05 1.36969441e+02]\n",
      "[2.79942222e+02 3.00418230e+01 8.79066996e+03 7.90588871e+00\n",
      " 4.62475050e+00 1.05478029e+05 2.69823205e+02 1.88954219e+04\n",
      " 1.92884941e+05 5.30807209e+01]\n",
      "----------16----------\n",
      "[2.23103183e-01 6.08677365e-01 1.80229026e-01 2.51212809e-01\n",
      " 3.51774334e-01 3.57394440e-01 4.31625258e+01 5.13008160e+03\n",
      " 1.00013555e+01 7.02303244e+00]\n",
      "[5.49658958e-01 2.51684258e+00 2.32722645e-01 7.11358703e-01\n",
      " 9.51727718e-01 3.01233111e+00 8.13888787e+01 1.01020858e+04\n",
      " 1.42438103e+01 1.27897009e+01]\n",
      "----------32----------\n",
      "[8.39544059e+00 1.82021186e+03 8.95093336e-01 6.37439516e+02\n",
      " 4.62994011e-01 9.79303072e+04 4.23693016e+03 1.50809572e+02\n",
      " 1.65437023e+03 1.55426450e+02]\n",
      "[1.01678613e+01 2.24113376e+03 1.68225974e+00 6.69611966e+02\n",
      " 1.18665468e+00 4.25739134e+05 1.65095494e+04 2.11066102e+02\n",
      " 6.08357375e+02 2.05800205e+02]\n",
      "----------64----------\n",
      "[9.10198642e-01 1.46337350e+01 2.96126721e+01 1.00816280e+00\n",
      " 3.74390817e+00 4.41377703e+01 1.52049540e+02 2.77159330e+05\n",
      " 3.11835791e+03 2.60384550e+04]\n",
      "[2.71647455e-01 1.69037665e+00 1.02413557e+01 2.42612957e-01\n",
      " 7.61897215e-01 3.81387311e+01 3.66867516e+01 2.12652235e+04\n",
      " 7.76456605e+02 1.60923965e+04]\n",
      "----------128----------\n"
     ]
    }
   ],
   "source": [
    "for N in [8, 16, 32, 64, 128]:\n",
    "    dr_est_values, cdl_est_values = train_esm(N, 20)\n",
    "    print(np.array(cdl_est_values).mean(axis=0))\n",
    "    print(np.array(dr_est_values).mean(axis=0))\n",
    "    print(\"--\"*5 + str(N)+\"--\"*5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffscm_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
