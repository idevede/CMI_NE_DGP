{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy.linalg import det\n",
    "\n",
    "import CMINE_lib as CMINE\n",
    "# from Guassian_variables import Data_guassian\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import itertools\n",
    "\n",
    "np.random.seed(37)\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import math\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(value, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable implementation of the operation\n",
    "    value.exp().sum(dim, keepdim).log()\n",
    "    \"\"\"\n",
    "    # TODO: torch.max(value, dim=None) threw an error at time of writing\n",
    "    if dim is not None:\n",
    "        m, _ = torch.max(value, dim=dim, keepdim=True)\n",
    "        value0 = value - m\n",
    "        if keepdim is False:\n",
    "            m = m.squeeze(dim)\n",
    "        return m + torch.log(torch.sum(torch.exp(value0),\n",
    "                                       dim=dim, keepdim=keepdim))\n",
    "    else:\n",
    "        m = torch.max(value)\n",
    "        sum_exp = torch.sum(torch.exp(value - m))\n",
    "        if isinstance(sum_exp, Number):\n",
    "            return m + math.log(sum_exp)\n",
    "        else:\n",
    "            return m + torch.log(sum_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.CMI import DR_CMI, CDL_CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim = 5\n",
    "batch_size = 64\n",
    "#dataset = CMINE.create_dataset_DGP( Dim=5, N=batch_size)\n",
    "dataset = CMINE.create_dataset_DGP_binary_A( Dim=5, N=batch_size)\n",
    "s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "a = torch.from_numpy(dataset[2]).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dim = 2*Dim\n",
    "\n",
    "hidden_size = 15\n",
    "learning_rate = 0.005\n",
    "training_steps = 10\n",
    "\n",
    "cubic = False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dr(N = 64, training_steps = 10):\n",
    "    torch.cuda.empty_cache()\n",
    "    model_dr = DR_CMI(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "    optimizer_dr = torch.optim.Adam(model_dr.parameters(), learning_rate)\n",
    "    dr_est_values = []\n",
    "    for step in range(training_steps):\n",
    "        #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "        dataset = CMINE.create_dataset_DGP_binary_A(Dim=Dim, N=N)\n",
    "        s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "        s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "        a = torch.from_numpy(dataset[2]).float().cuda()\n",
    "\n",
    "        batch_x = torch.cat([s_t,a], dim=1)\n",
    "        batch_y = s_next\n",
    "        model_dr.eval()\n",
    "        drs = model_dr(batch_x, batch_y)\n",
    "        #mi_est_values.append(cmi)\n",
    "        dr_est_values.append(drs)\n",
    "        model_dr.train() \n",
    "\n",
    "        model_loss = model_dr.learning_loss(batch_x, batch_y)\n",
    "\n",
    "        optimizer_dr.zero_grad()\n",
    "        model_loss.backward(retain_graph=True)\n",
    "        optimizer_dr.step()\n",
    "\n",
    "        del batch_x, batch_y\n",
    "        torch.cuda.empty_cache()\n",
    "    return dr_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cdl(N = 64, training_steps = 10):\n",
    "    torch.cuda.empty_cache()\n",
    "    model_cdl = CDL_CMI(sample_dim + 1, sample_dim, hidden_size).cuda()\n",
    "    optimizer_cdl = torch.optim.Adam(model_cdl.parameters(), learning_rate)\n",
    "    cdl_est_values = []\n",
    "    for step in range(training_steps):\n",
    "        #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "        dataset = CMINE.create_dataset_DGP_binary_A(Dim=Dim, N=64)\n",
    "        s_t = torch.from_numpy(dataset[0]).float().cuda()\n",
    "        s_next = torch.from_numpy(dataset[1]).float().cuda()\n",
    "        a = torch.from_numpy(dataset[2]).float().cuda()\n",
    "\n",
    "        batch_x = torch.cat([s_t,a], dim=1)\n",
    "        batch_y = s_next\n",
    "        model_cdl.eval()\n",
    "        cdl_cmi = model_cdl(batch_x, batch_y)\n",
    "        cdl_est_values.append(cdl_cmi)\n",
    "        model_cdl.train() \n",
    "\n",
    "        model_loss = model_cdl.learning_loss(batch_x, batch_y)\n",
    "\n",
    "        optimizer_cdl.zero_grad()\n",
    "        model_loss.backward(retain_graph=True)\n",
    "        optimizer_cdl.step()\n",
    "\n",
    "        del batch_x, batch_y\n",
    "        torch.cuda.empty_cache()\n",
    "    return cdl_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdl_est_values = train_cdl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_est_values = train_dr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.62909881 31.90293879  3.32989618  2.37203364 40.20621789  2.33121245\n",
      "  0.10007804  4.64158957  0.17156096 34.20440767]\n",
      "[1.67182227e+01 2.13185132e+01 1.74296744e+01 1.64255251e+01\n",
      " 1.87672516e+01 1.52023465e+03 2.41713650e+04 5.81954119e+07\n",
      " 1.12470102e+04 1.75729985e+04]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.30239090e+00 7.05152936e+00 8.23540059e+00 5.79760796e+00\n",
      " 7.20315365e+00 2.12945217e+05 1.50455859e+02 2.78672594e+02\n",
      " 2.27193331e+02 7.37535593e+03]\n",
      "[6.10654989e+03 1.55910844e+05 3.77279128e+04 1.58046943e+11\n",
      " 3.84559755e+07 2.88183968e+09 1.70990210e+06 6.64867495e+05\n",
      " 7.54625585e+06 3.09346798e+11]\n"
     ]
    }
   ],
   "source": [
    "N = 128\n",
    "cdl_est_values = train_cdl(N)\n",
    "dr_est_values = train_dr(N)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.22894816  0.53415195  0.17980211  0.13757467  0.99465214 65.07050759\n",
      "  4.91550556 16.42847439  3.3649228   1.53744228]\n",
      "[5.39664560e+03 5.35883037e+03 5.52185233e+03 5.56562032e+03\n",
      " 5.17552405e+03 1.64288803e+05 5.02380312e+04 5.52713212e+07\n",
      " 2.11297229e+10 1.16834368e+08]\n"
     ]
    }
   ],
   "source": [
    "N = 32\n",
    "cdl_est_values = train_cdl(N)\n",
    "dr_est_values = train_dr(N)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.78701690e+00 9.01703398e+02 7.79684412e+00 5.26387394e+00\n",
      " 1.29594241e+01 1.77291970e+06 8.20365912e+01 9.48841043e+01\n",
      " 1.01327541e+03 1.45746310e+02]\n",
      "[1.51966064e+05 2.71351952e-01 7.09830511e-01 6.07903015e-01\n",
      " 5.05081787e+00 1.48763132e-01 7.62969087e-01 4.27091030e-01\n",
      " 2.83229789e+01 2.05515325e+02]\n"
     ]
    }
   ],
   "source": [
    "N = 16\n",
    "cdl_est_values = train_cdl(N)\n",
    "dr_est_values = train_dr(N)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.31943605e+04 1.71830261e+08 6.60621143e+04 1.83854909e+05\n",
      " 6.29557521e+04 3.95083027e+09 5.30933075e+05 3.03847897e+05\n",
      " 3.01877772e+06 9.41156254e+05]\n",
      "[1.45674717e+05 5.62305784e+05 1.31564423e+05 1.34648689e+05\n",
      " 1.32427251e+06 2.39606343e+09 1.46911331e+14 6.66713691e+09\n",
      " 1.28531635e+08 2.40902858e+09]\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "training_step = 100\n",
    "cdl_est_values = train_cdl(N, training_step)\n",
    "dr_est_values = train_dr(N, training_step)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.68653295e+04 8.02705649e+00 1.19907736e+03 3.14780780e+01\n",
      " 3.98932782e+01 8.38730004e+05 3.92318122e+03 6.95953489e+04\n",
      " 1.22019822e+05 3.48546747e+06]\n",
      "[9.74688966e+03 7.74597234e+03 2.96815940e+09 6.31418542e+03\n",
      " 6.20089638e+03 1.22671743e+06 3.68697284e+09 4.77083438e+06\n",
      " 1.44713419e+07 1.88002237e+07]\n"
     ]
    }
   ],
   "source": [
    "N = 32\n",
    "training_step = 100\n",
    "cdl_est_values = train_cdl(N, training_step)\n",
    "dr_est_values = train_dr(N, training_step)\n",
    "print(np.array(cdl_est_values).mean(axis=0))\n",
    "print(np.array(dr_est_values).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffscm_gpu",
   "language": "python",
   "name": "diffscm_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
